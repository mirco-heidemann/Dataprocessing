---
title: "Prepare GVZ Data for the scClim Project"
subtitle: "Exposure and Hail Loss Data"
author: "Mirco Heidemann"
date: "03/2022"
output: pdf_document
---
Prepare the GVZ exposure from 01.01.2022 and hail loss data from 01.01.2000 to 15.03.2022 for the scClim Project. scClim - A nationwide program to establish a seamless chain from climate and weather modeling to the quantification of hail impacts.
The data goes to Timo Schmid, a doctoral student in the Weather and Climate Risks group of David Bresch at the ETH ZÃ¼rich.
Email: timo.schmid@usys.ethz.ch

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(leaflet)

## Setup paths
path_data <- "../Data/"
path_output <- "../Output/"
```

**Attribute for exposure data:**
- VersicherungsID
- Versicherungssumme
- Volumen
- Baujahr
- Nutzung
- Nutzungscode
- KoordinateNord
- KoordinateOst
- Adresse

**Attribute for loss data:**
- VersicherungsID
- Versicherungssumme
- Volumen
- Baujahr
- Nutzung
- Nutzungscode
- KoordinateNord
- KoordinateOst
- Adresse

- Schadennummer
- Schadendatum
- Schadensumme

- Index

Read **exposure** into a data frame. Where "Versicherungssumme" equals zero, volumen and coordinates are "NULL", the building is "fremdversichert", meaning there is no police at gvz. Remove those buildings.

Read **loss** into data frames. Read only loss attributes and take police data via joining the exposure data. This means, we have loss data that correspond with the actual exposure from 01.01.2022! The loss data of demolished buildings, however, are lost.

Read GVZ-Index for indexing losses and portfolio from 2019 for the coordinates.
```{r}
file_name_exp <- paste0(path_data, "GVZ_Portfolio_Stand_20220101.csv")
file_name_loss <- paste0(path_data, "GemDat_Schaden_Export_Ng_20220315.csv")
index_gvz <- paste0(path_data, "Versicherungsindex_GVZ.csv")

# Read exposure data
df_orig_exp <- read_delim(file_name_exp, delim = ";")

# Read loss data
df_orig_loss <- read_delim(file_name_loss, delim = ";",
                           # locale = locale(grouping_mark = "'"),
                           col_select = c(2, 4:6, 9))

# Read "GVZ Versicherungs Index"
df_index <- read_delim(index_gvz, delim = ";",
                       col_select = c(1,3)) %>% 
  mutate(Jahr = format(as.Date(Jahr, "%d.%m.%Y"), "%Y")) %>% 
  rename(Index = `Versicherungsindex GVZ`)
```

Data wrangling: Rename, re-shape, join gvz-index and coordinates, filter non-Na's, only hail losses, ...
Modify wrong reported Baujahr as follows:
- Beyond 2022: Set to 2022
- Na: Set to median

```{r}
# Wrangling exposure data
df_exp <- df_orig_exp %>% 
  filter(Versicherungssumme != 0) %>% 
  mutate(Volumen = as.integer(Volumen),
         Baujahr = ifelse(Baujahr > 2022, 2022, Baujahr),
         Baujahr = ifelse(is.na(Baujahr), median(Baujahr, na.rm = TRUE), Baujahr),
         KoordinateNord = as.numeric(KoordinateNord),
         KoordinateOst = as.numeric(KoordinateOst)) %>% 
  filter(!is.na(KoordinateNord))

# Wrangling loss data
df_loss <- df_orig_loss %>% 
  rename(Schadenursache = ClaimCausationDetail,
         Schadennummer = ObjectClaimNumber,
         Schadendatum = ClaimIncidentDate,
         Schadensumme = ClaimSumBuilding,
         GebNr = BuildingAssuranceNumberCant) %>% 
  mutate(Schadendatum = as.Date(Schadendatum, "%d.%m.%Y"),
         Schadenjahr = format(Schadendatum, "%Y")) %>%
  filter(Schadenursache == "211 Hagel",
         Schadendatum >= as.Date(format("01.01.2000"), "%d.%m.%Y")) %>% 
  left_join(df_index, by = c("Schadenjahr" = "Jahr"))

## Merging loss to exposure data
df_loss_complete <- df_exp %>% 
  ## !! Remember: Loss data without exposure - demolished buildings - are lost
  inner_join(df_loss, by = c("VersicherungsID" = "GebNr")) %>% 
  mutate(Schadendatum = format(Schadendatum, "%d%m%Y")) %>% 
  dplyr::select(-c(Schadenjahr, Schadenursache))

summary(df_exp)
summary(df_loss_complete)

print(paste0(dim(df_loss)[1]-dim(df_loss_complete)[1], " losses without a current building belonging to demolished buildings. This claims will be lost."))
```

Checking coordinates with a simple leaflet map.
First, transform the LV95 CH-Coords to WGS84.
```{r}
# KoordinateOst, KoordinateNord
p = st_point(c(2678443, 1235256))
p = st_point(cbind(df_exp$KoordinateOst[1:5], df_exp$KoordinateNord[1:5]))

sfc = st_sfc(p, crs = 2056)
sfc
p_trans <- st_transform(sfc, 4326)
p_trans




coordinates(data.event) <- c("geox","geoy")

  # proj4string(data.event) <- CRS("+init=epsg:21781")
  proj4string(data.event) <- CRS("+init=epsg:2056")   # LV95

  ## Transform the data to WGS84
  data.event.WGS84 <- spTransform(data.event, CRS("+init=epsg:4326"))

  data.event.WGS84$X <- as.numeric(data.event.WGS84$geox)
  data.event.WGS84$Y <- as.numeric(data.event.WGS84$geoy)



epsg2056 <- leafletCRS(crsClass = "L.Proj.CRS", code = "EPSG:2056",
  proj4def = "+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs",
  resolutions = c(4000, 2000),
  origin = c(2420000, 1350000))

epsg2163 <- leafletCRS(
  crsClass = "L.Proj.CRS",
  code = "EPSG:2163",
  proj4def = "+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +a=6370997 +b=6370997 +units=m +no_defs",
  resolutions = 2^(16:7))
```
Plot the leaflet map
```{r}
leaflet(data = df_exp[1:20,], options = leafletOptions(crs = epsg2163)) %>%
  #setView(2420000, 1350000, 9) %>%
  addTiles()


  setView(lng=8.60, lat=47.4, zoom = 9) %>% 
  # addTiles() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addCircleMarkers(~long, ~lat)
```

Write data as csv files to disk.
```{r}
write_excel_csv(df_exp, paste0(path_output, "GVZ_Exposure_202201.csv"), delim = ";")
write_excel_csv(df_loss_complete, paste0(path_output, "GVZ_Hail_Loss_200001_to_202203.csv"), delim = ";")
```

