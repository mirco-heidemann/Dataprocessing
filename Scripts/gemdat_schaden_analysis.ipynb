{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis - Schadendaten aus GemDat \n",
    "Mirco Heidemann, 05/07/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mirco/miniconda3/envs/datascience/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/mirco/miniconda3/envs/datascience/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os as os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at source csv file\n",
    "# !head -n 3 data/A_Schadendatenper31.05.2018_9639.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV into a pandas data frame (df)\n",
    "df = pd.read_csv(\"data/A_Schadendatenper31.05.2018_9639.csv\", delimiter=';', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first five rows, analog to R's head(df)\n",
    "# df.head()\n",
    "\n",
    "# pandas equivalents for R functions str()\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename and arrange the pandas data frame, specify datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns: 'alter_name': 'neuer_name'\n",
    "df.rename(columns={'GebaeudeId': 'geb_id',\n",
    "                   'GebaeudeSuchbegriff': 'geb_nr',\n",
    "                   'SchadenVersicherungWert': 'vers_sum',\n",
    "                   'GebaeudeBaujahr': 'baujahr',\n",
    "                   'GebaeudeGemeindeName': 'gemeinde',\n",
    "                   'Ausdr2': 'gemeinde_id',\n",
    "                   'GebaeudeZweckCode': 'zwk_code',\n",
    "                   'GebaeudeZweckText': 'zwk_code_text',\n",
    "                   'SchadenId': 'schaden_id',\n",
    "                   'SchadenNr': 'schaden_nr',\n",
    "                   'SchadenDatum': 'schaden_datum',\n",
    "                   'SchadenSumme': 'schaden_sum',\n",
    "                   'SchadenArtBezeichnung': 'schaden_art',\n",
    "                   'CodTextDt': 'schaden_code',\n",
    "                   'StcTextDt': 'status'},\n",
    "          inplace = True) # rename the existing DataFrame (rather than creating a copy)\n",
    "\n",
    "# converting schaden_datum to date format\n",
    "df['schaden_datum'] = pd.to_datetime(df.schaden_datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting columns\n",
    "# df_selected = df[['geb_id', 'schaden_id', 'schaden_datum']]\n",
    "\n",
    "# write the new csv\n",
    "# df_new.to_csv('schad_example_new.csv', index = False, encoding = \"ISO-8859-1\") # encoding = \"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "df_schad = df.drop(columns=['Erstellung', 'Ausdr1', 'GebaeudeStrasse', 'GebaeudeHausNr', 'GebaeudePlz',\n",
    "                          'GebaeudeOrt', 'Ausdr3', 'GebaeudeVolumen', 'EdiStcDis', 'EdiAfDat'])\n",
    "# df_schad.info()\n",
    "# df_schad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Index losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read index csv and rename colums\n",
    "gvz_index = pd.read_csv(\"../GVZ_Portfolio/versicherungsindex_gvz.csv\", sep = ';')\n",
    "\n",
    "gvz_index = gvz_index.rename(columns={'Versicherungsindex GVZ': 'index',\n",
    "                             'Jahr': 'jahr'})\n",
    "\n",
    "gvz_index.jahr = pd.to_datetime(gvz_index.jahr)\n",
    "gvz_index.jahr = gvz_index.jahr.dt.strftime('%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year of loss as new column\n",
    "df_schad['jahr'] = df_schad['schaden_datum'].dt.strftime('%Y')\n",
    "\n",
    "# merge gvz-index to df_schad\n",
    "df_schad = pd.merge(df_schad,\n",
    "                 gvz_index[['jahr', 'index']],\n",
    "                 on='jahr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate indexed loss\n",
    "df_schad['schaden_index'] = gvz_index['index'].max() / df_schad['index'] * df_schad['schaden_sum']\n",
    "# df_schad.sort_values(by = \"schaden_datum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only elementar losses greater than zero and aggregate it to yearly losses for each peril (flood, hail, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing scientific notation in pandas\n",
    "pd.options.display.float_format = '{:20,.0f}'.format\n",
    "\n",
    "# only elementar losses greater than zero\n",
    "df_elementar = df_schad[(df_schad['schaden_art'] == \"Elementar\") & (df_schad['schaden_sum'] > 0)]\n",
    "\n",
    "# group by 'schaden_code' and 'jahr'\n",
    "grouped = df_elementar.groupby(['schaden_code', 'jahr'])\n",
    "\n",
    "# once the GroupBy object ('grouped') has been created, aggregate it\n",
    "by_peril = grouped['schaden_index'].aggregate([np.sum, np.mean, np.median, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting only losses from one peril and aggregate it to yearly losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by 'schaden_code'\n",
    "grouped_peril = df_elementar.groupby('schaden_code')\n",
    "\n",
    "# selecting a single group, eg. 'flood'\n",
    "by_single_peril = grouped_peril.get_group('3 Hochwasser, Überschwemmung')\n",
    "\n",
    "# group by 'jahr'\n",
    "by_single_peril = by_single_peril.groupby('jahr')\n",
    "\n",
    "# aggregate it to yearly losses\n",
    "by_single_peril = by_single_peril['schaden_index'].aggregate([np.sum, np.size, np.mean, np.median, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrange df that jahr is the index and for each peril a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by 'schaden_code' and 'jahr'\n",
    "grouped = df_elementar.groupby(['schaden_code', 'jahr'])\n",
    "\n",
    "# aggregate 'schaden_index' per year, resetting indexes\n",
    "by_jahr = grouped['schaden_index'].aggregate([np.sum]).reset_index()\n",
    "\n",
    "# spread by schaden_code: index = jahr, columns = schaden_code, values = sum\n",
    "by_jahr = by_jahr.pivot(index = 'jahr', columns = 'schaden_code', values='sum')\n",
    "\n",
    "# rename columns\n",
    "by_jahr = by_jahr.rename(columns={'.': 'Unbekannt', '1 Sturm': 'Sturm', '2 Hagel': 'Hagel',\n",
    "                                  '3 Hochwasser, Überschwemmung': 'Flut',\n",
    "                                  '4 Erdrutsch, Steinschlag': 'Erdrutsch_Steinschlag',\n",
    "                                  '5 Schneedruck': 'Schneedruck', '6 Lawinen': 'Dachlawine'})\n",
    "\n",
    "# replace NAs with zero\n",
    "by_jahr.fillna(0, inplace=True)\n",
    "\n",
    "# new categorie 'Rest' = Unbekannt + Erdrutsch_Steinschlag + Schneedruck + Dachlawine\n",
    "by_jahr['Rest'] = by_jahr['Unbekannt'] + by_jahr['Erdrutsch_Steinschlag'] +\\\n",
    "by_jahr['Schneedruck'] + by_jahr['Dachlawine']\n",
    "\n",
    "# dropping the unused columns\n",
    "by_jahr = by_jahr.drop(columns=['Unbekannt', 'Erdrutsch_Steinschlag', 'Schneedruck', 'Dachlawine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot with Altair\n",
    "Note: 'jahr' is the index and not a column of the grouped data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "# for the notebook only (not for JupyterLab) run this command once per session\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index, make 'jahr' to a column in the data frame\n",
    "df_by_jahr = by_jahr.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_by_jahr).mark_bar().encode(\n",
    "    x='jahr',\n",
    "    y='Hagel'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacked Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping df for the stacked bar chart\n",
    "df_melt = df_by_jahr.melt(id_vars = 'jahr')\n",
    "\n",
    "alt.Chart(df_melt).mark_bar().encode(\n",
    "    # tell Altair which field to use for color segmentation \n",
    "    alt.Color('schaden_code',\n",
    "        legend=alt.Legend(title='Schadenursache'),\n",
    "        scale=alt.Scale(\n",
    "            domain=['Sturm', 'Hagel', 'Flut', 'Rest'],\n",
    "            range=['#e7ba42', '#c7c7c7', '#aec7e8', '#1f77b4']\n",
    "        ),\n",
    "    ),\n",
    "    # tell Altair which field to group columns on\n",
    "    alt.X('jahr',\n",
    "        axis=alt.Axis(title='jahr'),\n",
    "         ),\n",
    "    # tell Altair which field to use as Y values and how to calculate\n",
    "    alt.Y('sum(value)',\n",
    "       axis=alt.Axis(title='indexierte Schadensumme'),\n",
    "      ),\n",
    ") #.properties(width=300, height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
